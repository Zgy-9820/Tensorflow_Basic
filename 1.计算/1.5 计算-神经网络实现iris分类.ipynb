{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "04-神经网络实现iris分类.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "u65QM4mP4lxF"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_tFLurA4lxM"
      },
      "source": [
        "## 1. 准备数据"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZANlWKur4lxN"
      },
      "source": [
        "### 1.1)数据集读入"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BqP6-rW4lxN"
      },
      "source": [
        "x_data = datasets.load_iris().data\n",
        "y_data = datasets.load_iris().target"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9dHOkyt4lxS"
      },
      "source": [
        "### 1.2)数据集乱序"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXQaTQ_b4lxT"
      },
      "source": [
        "np.random.seed(116)\n",
        "np.random.shuffle(x_data)\n",
        "np.random.seed(116)\n",
        "np.random.shuffle(y_data)\n",
        "tf.random.set_seed(116)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPl_Nul_4lxX"
      },
      "source": [
        "### 1.3)数据集分为训练集和测试集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDs92uW34lxY"
      },
      "source": [
        "x_train = x_data[:-30]\n",
        "y_train = y_data[:-30]\n",
        "x_test = x_data[-30:]\n",
        "y_test = y_data[-30:]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16FZYG6C4lxc"
      },
      "source": [
        "### ps.转换数据类型(防止后面矩阵乘法出现错误)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6Ohn2Z24lxd"
      },
      "source": [
        "x_train = tf.cast(x_train, tf.float32)\n",
        "x_test = tf.cast(x_test, tf.float32)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRlmxp4u4lxg"
      },
      "source": [
        "### 1.4)配成[输入特征, 标签]对，每次喂入一小撮(batch)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_YpwthK4lxh"
      },
      "source": [
        "train_db = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\n",
        "test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUW4n2RN4lxm"
      },
      "source": [
        "## 2. 搭建网络"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8VKuVYg4lxn"
      },
      "source": [
        "### 定义神经网络中所有可训练的参数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNdFC0Qw4lxn"
      },
      "source": [
        "w1 = tf.Variable(tf.random.truncated_normal([4, 3], stddev=0.1, seed=1))\n",
        "b1 = tf.Variable(tf.random.truncated_normal([3], stddev=0.1, seed=1))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKr0Ajpd4lxq"
      },
      "source": [
        "## 3. 参数优化/训练结果"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q36wNUl4lxr"
      },
      "source": [
        "### 3.1)定义参数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gx7OXll14lxs"
      },
      "source": [
        "lr = 0.1\n",
        "train_loss_results = []\n",
        "test_acc = []\n",
        "epoch = 500\n",
        "loss_all = 0"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTiwhiBN4lxv"
      },
      "source": [
        "### 3.2)训练和测试"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjN2tM_34lxw",
        "outputId": "99aaae43-f9cb-4e8c-a779-0a64468fa413",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 训练部分\n",
        "for epoch in range(epoch):  #数据集级别的循环，每个epoch循环一次数据集\n",
        "    for step, (x_train, y_train) in enumerate(train_db):  #batch级别的循环 ，每个step循环一个batch\n",
        "        with tf.GradientTape() as tape:  # with结构记录梯度信息\n",
        "            y = tf.matmul(x_train, w1) + b1  # 神经网络乘加运算\n",
        "            y = tf.nn.softmax(y)  # 使输出y符合概率分布（此操作后与独热码同量级，可相减求loss）\n",
        "            y_ = tf.one_hot(y_train, depth=3)  # 将标签值转换为独热码格式，方便计算loss和accuracy\n",
        "            loss = tf.reduce_mean(tf.square(y_ - y))  # 采用均方误差损失函数mse = mean(sum(y-out)^2)\n",
        "            loss_all += loss.numpy()  # 将每个step计算出的loss累加，为后续求loss平均值提供数据，这样计算的loss更准确\n",
        "        # 计算loss对各个参数的梯度\n",
        "        grads = tape.gradient(loss, [w1, b1])\n",
        "\n",
        "        # 实现梯度更新 w1 = w1 - lr * w1_grad    b = b - lr * b_grad\n",
        "        w1.assign_sub(lr * grads[0])  # 参数w1自更新\n",
        "        b1.assign_sub(lr * grads[1])  # 参数b自更新\n",
        "\n",
        "    # 每个epoch，打印loss信息\n",
        "    print(\"Epoch {}, loss: {}\".format(epoch, loss_all/4))\n",
        "    train_loss_results.append(loss_all / 4)  # 将4个step的loss求平均记录在此变量中\n",
        "    loss_all = 0  # loss_all归零，为记录下一个epoch的loss做准备\n",
        "\n",
        "    # 测试部分\n",
        "    # total_correct为预测对的样本个数, total_number为测试的总样本数，将这两个变量都初始化为0\n",
        "    total_correct, total_number = 0, 0\n",
        "    for x_test, y_test in test_db:\n",
        "        # 使用更新后的参数进行预测\n",
        "        y = tf.matmul(x_test, w1) + b1\n",
        "        y = tf.nn.softmax(y)\n",
        "        pred = tf.argmax(y, axis=1)  # 返回y中最大值的索引，即预测的分类\n",
        "        # 将pred转换为y_test的数据类型\n",
        "        pred = tf.cast(pred, dtype=y_test.dtype)\n",
        "        # 若分类正确，则correct=1，否则为0，将bool型的结果转换为int型\n",
        "        correct = tf.cast(tf.equal(pred, y_test), dtype=tf.int32)\n",
        "        # 将每个batch的correct数加起来\n",
        "        correct = tf.reduce_sum(correct)\n",
        "        # 将所有batch中的correct数加起来\n",
        "        total_correct += int(correct)\n",
        "        # total_number为测试的总样本数，也就是x_test的行数，shape[0]返回变量的行数\n",
        "        total_number += x_test.shape[0]\n",
        "    # 总的准确率等于total_correct/total_number\n",
        "    acc = total_correct / total_number\n",
        "    test_acc.append(acc)\n",
        "    print(\"Test_acc:\", acc)\n",
        "    print(\"--------------------------\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, loss: 0.2821310982108116\n",
            "Test_acc: 0.16666666666666666\n",
            "--------------------------\n",
            "Epoch 1, loss: 0.25459613651037216\n",
            "Test_acc: 0.16666666666666666\n",
            "--------------------------\n",
            "Epoch 2, loss: 0.22570249810814857\n",
            "Test_acc: 0.16666666666666666\n",
            "--------------------------\n",
            "Epoch 3, loss: 0.21028399839997292\n",
            "Test_acc: 0.16666666666666666\n",
            "--------------------------\n",
            "Epoch 4, loss: 0.19942265003919601\n",
            "Test_acc: 0.16666666666666666\n",
            "--------------------------\n",
            "Epoch 5, loss: 0.18873638659715652\n",
            "Test_acc: 0.5\n",
            "--------------------------\n",
            "Epoch 6, loss: 0.17851299047470093\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 7, loss: 0.16922876238822937\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 8, loss: 0.16107673570513725\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 9, loss: 0.15404685214161873\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 10, loss: 0.14802726358175278\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 11, loss: 0.14287303388118744\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 12, loss: 0.1384414155036211\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 13, loss: 0.13460607640445232\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 14, loss: 0.1312607228755951\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 15, loss: 0.12831821851432323\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 16, loss: 0.12570794485509396\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 17, loss: 0.12337298691272736\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 18, loss: 0.12126746028661728\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 19, loss: 0.11935432627797127\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 20, loss: 0.11760355532169342\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 21, loss: 0.11599067598581314\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 22, loss: 0.11449568346142769\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 23, loss: 0.11310207471251488\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 24, loss: 0.11179621517658234\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 25, loss: 0.11056671850383282\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 26, loss: 0.10940408147871494\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 27, loss: 0.10830027982592583\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 28, loss: 0.10724854655563831\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 29, loss: 0.10624312795698643\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 30, loss: 0.1052790954709053\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 31, loss: 0.10435221716761589\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 32, loss: 0.10345886461436749\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 33, loss: 0.1025958750396967\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 34, loss: 0.10176052711904049\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 35, loss: 0.10095042549073696\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 36, loss: 0.10016347281634808\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 37, loss: 0.09939784556627274\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 38, loss: 0.09865193255245686\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 39, loss: 0.09792428836226463\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 40, loss: 0.09721365384757519\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 41, loss: 0.09651889279484749\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 42, loss: 0.09583901427686214\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 43, loss: 0.09517310187220573\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 44, loss: 0.09452036768198013\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 45, loss: 0.09388007037341595\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 46, loss: 0.09325155802071095\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 47, loss: 0.09263424947857857\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 48, loss: 0.09202759526669979\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 49, loss: 0.09143111668527126\n",
            "Test_acc: 0.5333333333333333\n",
            "--------------------------\n",
            "Epoch 50, loss: 0.09084436483681202\n",
            "Test_acc: 0.5666666666666667\n",
            "--------------------------\n",
            "Epoch 51, loss: 0.09026693738996983\n",
            "Test_acc: 0.5666666666666667\n",
            "--------------------------\n",
            "Epoch 52, loss: 0.08969846367835999\n",
            "Test_acc: 0.5666666666666667\n",
            "--------------------------\n",
            "Epoch 53, loss: 0.08913860470056534\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 54, loss: 0.08858705125749111\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 55, loss: 0.08804351650178432\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 56, loss: 0.08750772848725319\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 57, loss: 0.08697944320738316\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 58, loss: 0.08645843155682087\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 59, loss: 0.08594449050724506\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 60, loss: 0.08543741330504417\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 61, loss: 0.08493702299892902\n",
            "Test_acc: 0.6\n",
            "--------------------------\n",
            "Epoch 62, loss: 0.08444313332438469\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 63, loss: 0.08395559899508953\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 64, loss: 0.08347426168620586\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 65, loss: 0.0829989816993475\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 66, loss: 0.08252961561083794\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 67, loss: 0.08206603676080704\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 68, loss: 0.08160812966525555\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 69, loss: 0.08115578629076481\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 70, loss: 0.08070887997746468\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 71, loss: 0.08026731573045254\n",
            "Test_acc: 0.6333333333333333\n",
            "--------------------------\n",
            "Epoch 72, loss: 0.07983099482953548\n",
            "Test_acc: 0.6666666666666666\n",
            "--------------------------\n",
            "Epoch 73, loss: 0.0793998222798109\n",
            "Test_acc: 0.6666666666666666\n",
            "--------------------------\n",
            "Epoch 74, loss: 0.07897370308637619\n",
            "Test_acc: 0.6666666666666666\n",
            "--------------------------\n",
            "Epoch 75, loss: 0.07855254970490932\n",
            "Test_acc: 0.7\n",
            "--------------------------\n",
            "Epoch 76, loss: 0.0781362783163786\n",
            "Test_acc: 0.7\n",
            "--------------------------\n",
            "Epoch 77, loss: 0.07772481255233288\n",
            "Test_acc: 0.7\n",
            "--------------------------\n",
            "Epoch 78, loss: 0.07731807045638561\n",
            "Test_acc: 0.7\n",
            "--------------------------\n",
            "Epoch 79, loss: 0.07691597566008568\n",
            "Test_acc: 0.7\n",
            "--------------------------\n",
            "Epoch 80, loss: 0.07651845552027225\n",
            "Test_acc: 0.7\n",
            "--------------------------\n",
            "Epoch 81, loss: 0.07612544298171997\n",
            "Test_acc: 0.7333333333333333\n",
            "--------------------------\n",
            "Epoch 82, loss: 0.07573686353862286\n",
            "Test_acc: 0.7333333333333333\n",
            "--------------------------\n",
            "Epoch 83, loss: 0.07535265572369099\n",
            "Test_acc: 0.7333333333333333\n",
            "--------------------------\n",
            "Epoch 84, loss: 0.07497275806963444\n",
            "Test_acc: 0.7333333333333333\n",
            "--------------------------\n",
            "Epoch 85, loss: 0.0745970867574215\n",
            "Test_acc: 0.7666666666666667\n",
            "--------------------------\n",
            "Epoch 86, loss: 0.07422560080885887\n",
            "Test_acc: 0.7666666666666667\n",
            "--------------------------\n",
            "Epoch 87, loss: 0.07385823223739862\n",
            "Test_acc: 0.7666666666666667\n",
            "--------------------------\n",
            "Epoch 88, loss: 0.07349492330104113\n",
            "Test_acc: 0.7666666666666667\n",
            "--------------------------\n",
            "Epoch 89, loss: 0.07313562370836735\n",
            "Test_acc: 0.7666666666666667\n",
            "--------------------------\n",
            "Epoch 90, loss: 0.07278027012944221\n",
            "Test_acc: 0.7666666666666667\n",
            "--------------------------\n",
            "Epoch 91, loss: 0.0724288010969758\n",
            "Test_acc: 0.7666666666666667\n",
            "--------------------------\n",
            "Epoch 92, loss: 0.07208117935806513\n",
            "Test_acc: 0.7666666666666667\n",
            "--------------------------\n",
            "Epoch 93, loss: 0.07173734065145254\n",
            "Test_acc: 0.8\n",
            "--------------------------\n",
            "Epoch 94, loss: 0.07139724306762218\n",
            "Test_acc: 0.8\n",
            "--------------------------\n",
            "Epoch 95, loss: 0.07106082048267126\n",
            "Test_acc: 0.8\n",
            "--------------------------\n",
            "Epoch 96, loss: 0.07072803936898708\n",
            "Test_acc: 0.8\n",
            "--------------------------\n",
            "Epoch 97, loss: 0.0703988391906023\n",
            "Test_acc: 0.8\n",
            "--------------------------\n",
            "Epoch 98, loss: 0.07007318455725908\n",
            "Test_acc: 0.8333333333333334\n",
            "--------------------------\n",
            "Epoch 99, loss: 0.06975101213902235\n",
            "Test_acc: 0.8666666666666667\n",
            "--------------------------\n",
            "Epoch 100, loss: 0.06943229306489229\n",
            "Test_acc: 0.8666666666666667\n",
            "--------------------------\n",
            "Epoch 101, loss: 0.06911697518080473\n",
            "Test_acc: 0.8666666666666667\n",
            "--------------------------\n",
            "Epoch 102, loss: 0.06880501005798578\n",
            "Test_acc: 0.8666666666666667\n",
            "--------------------------\n",
            "Epoch 103, loss: 0.06849635299295187\n",
            "Test_acc: 0.8666666666666667\n",
            "--------------------------\n",
            "Epoch 104, loss: 0.06819096300750971\n",
            "Test_acc: 0.8666666666666667\n",
            "--------------------------\n",
            "Epoch 105, loss: 0.06788880284875631\n",
            "Test_acc: 0.8666666666666667\n",
            "--------------------------\n",
            "Epoch 106, loss: 0.0675898278132081\n",
            "Test_acc: 0.8666666666666667\n",
            "--------------------------\n",
            "Epoch 107, loss: 0.06729398854076862\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 108, loss: 0.06700124405324459\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 109, loss: 0.06671156454831362\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 110, loss: 0.06642491649836302\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 111, loss: 0.06614124123007059\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 112, loss: 0.0658605145290494\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 113, loss: 0.06558268796652555\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 114, loss: 0.06530773546546698\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 115, loss: 0.06503560673445463\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 116, loss: 0.06476627755910158\n",
            "Test_acc: 0.9\n",
            "--------------------------\n",
            "Epoch 117, loss: 0.06449970323592424\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 118, loss: 0.06423585768789053\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 119, loss: 0.0639747017994523\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 120, loss: 0.06371620204299688\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 121, loss: 0.0634603202342987\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 122, loss: 0.06320702657103539\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 123, loss: 0.06295627821236849\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 124, loss: 0.06270805187523365\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 125, loss: 0.06246231682598591\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 126, loss: 0.06221904419362545\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 127, loss: 0.06197819113731384\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 128, loss: 0.061739737167954445\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 129, loss: 0.06150364875793457\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 130, loss: 0.06126989144831896\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 131, loss: 0.061038440093398094\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 132, loss: 0.06080926675349474\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 133, loss: 0.06058233417570591\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 134, loss: 0.06035762373358011\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 135, loss: 0.060135108418762684\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 136, loss: 0.05991475656628609\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 137, loss: 0.05969653092324734\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 138, loss: 0.059480419382452965\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 139, loss: 0.05926638934761286\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 140, loss: 0.0590544156730175\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 141, loss: 0.05884446669369936\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 142, loss: 0.05863652750849724\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 143, loss: 0.058430569246411324\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 144, loss: 0.058226561173796654\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 145, loss: 0.05802448280155659\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 146, loss: 0.05782431084662676\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 147, loss: 0.0576260294765234\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 148, loss: 0.05742959212511778\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 149, loss: 0.05723499320447445\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 150, loss: 0.05704221408814192\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 151, loss: 0.05685122311115265\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 152, loss: 0.056661998853087425\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 153, loss: 0.05647451803088188\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 154, loss: 0.05628876481205225\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 155, loss: 0.056104715913534164\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 156, loss: 0.05592234618961811\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 157, loss: 0.05574163142591715\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 158, loss: 0.055562565103173256\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 159, loss: 0.055385115556418896\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 160, loss: 0.05520927254110575\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 161, loss: 0.055035010911524296\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 162, loss: 0.05486230552196503\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 163, loss: 0.05469114612787962\n",
            "Test_acc: 0.9333333333333333\n",
            "--------------------------\n",
            "Epoch 164, loss: 0.054521508514881134\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 165, loss: 0.0543533768504858\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 166, loss: 0.05418673437088728\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 167, loss: 0.05402155313640833\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 168, loss: 0.0538578387349844\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 169, loss: 0.05369554739445448\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 170, loss: 0.05353467911481857\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 171, loss: 0.05337520595639944\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 172, loss: 0.053217110224068165\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 173, loss: 0.05306038912385702\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 174, loss: 0.05290501657873392\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 175, loss: 0.05275097955018282\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 176, loss: 0.052598259411752224\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 177, loss: 0.05244683753699064\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 178, loss: 0.052296705543994904\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 179, loss: 0.052147846668958664\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 180, loss: 0.052000245079398155\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 181, loss: 0.05185388308018446\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 182, loss: 0.05170875322073698\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 183, loss: 0.051564838737249374\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 184, loss: 0.05142211355268955\n",
            "Test_acc: 0.9666666666666667\n",
            "--------------------------\n",
            "Epoch 185, loss: 0.05128058139234781\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 186, loss: 0.05114021431654692\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 187, loss: 0.05100100859999657\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 188, loss: 0.05086294189095497\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 189, loss: 0.05072601139545441\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 190, loss: 0.050590197555720806\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 191, loss: 0.05045549105852842\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 192, loss: 0.05032187048345804\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 193, loss: 0.05018933676183224\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 194, loss: 0.05005786754190922\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 195, loss: 0.049927457235753536\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 196, loss: 0.049798084422945976\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 197, loss: 0.04966974724084139\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 198, loss: 0.049542427994310856\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 199, loss: 0.04941612295806408\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 200, loss: 0.049290806986391544\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 201, loss: 0.0491664744913578\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 202, loss: 0.04904312081634998\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 203, loss: 0.048920733854174614\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 204, loss: 0.04879929218441248\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 205, loss: 0.04867880418896675\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 206, loss: 0.048559242859482765\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 207, loss: 0.048440602608025074\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 208, loss: 0.04832287039607763\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 209, loss: 0.04820604622364044\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 210, loss: 0.04809011146426201\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 211, loss: 0.04797505401074886\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 212, loss: 0.04786087851971388\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 213, loss: 0.04774755798280239\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 214, loss: 0.04763508774340153\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 215, loss: 0.04752346966415644\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 216, loss: 0.0474126860499382\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 217, loss: 0.047302717342972755\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 218, loss: 0.047193583101034164\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 219, loss: 0.04708524141460657\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 220, loss: 0.04697770904749632\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 221, loss: 0.046870965510606766\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 222, loss: 0.04676500242203474\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 223, loss: 0.046659817919135094\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 224, loss: 0.04655539244413376\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 225, loss: 0.046451729722321033\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 226, loss: 0.046348826959729195\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 227, loss: 0.04624664969742298\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 228, loss: 0.046145216561853886\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 229, loss: 0.046044507063925266\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 230, loss: 0.04594451654702425\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 231, loss: 0.045845236629247665\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 232, loss: 0.045746663585305214\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 233, loss: 0.0456487825140357\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 234, loss: 0.04555159993469715\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 235, loss: 0.04545509163290262\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 236, loss: 0.045359267853200436\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 237, loss: 0.045264105312526226\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 238, loss: 0.04516960773617029\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 239, loss: 0.04507576674222946\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 240, loss: 0.044982568360865116\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 241, loss: 0.044890021905303\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 242, loss: 0.044798110611736774\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 243, loss: 0.04470680933445692\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 244, loss: 0.04461614973843098\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 245, loss: 0.04452610481530428\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 246, loss: 0.04443667642772198\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 247, loss: 0.044347845017910004\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 248, loss: 0.044259609654545784\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 249, loss: 0.044171969406306744\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 250, loss: 0.04408491123467684\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 251, loss: 0.04399843979626894\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 252, loss: 0.043912542052567005\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 253, loss: 0.04382720962166786\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 254, loss: 0.043742443434894085\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 255, loss: 0.043658243492245674\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 256, loss: 0.04357459023594856\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 257, loss: 0.043491486459970474\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 258, loss: 0.04340892378240824\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 259, loss: 0.04332689754664898\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 260, loss: 0.043245408684015274\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 261, loss: 0.04316443484276533\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 262, loss: 0.043083999305963516\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 263, loss: 0.043004064820706844\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 264, loss: 0.04292465094476938\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 265, loss: 0.04284574370831251\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 266, loss: 0.04276733845472336\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 267, loss: 0.04268943518400192\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 268, loss: 0.042612009681761265\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 269, loss: 0.04253508895635605\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 270, loss: 0.04245864413678646\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 271, loss: 0.04238268453627825\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 272, loss: 0.04230719432234764\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 273, loss: 0.04223217815160751\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 274, loss: 0.04215762484818697\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 275, loss: 0.042083531618118286\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 276, loss: 0.04200989939272404\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 277, loss: 0.041936722584068775\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 278, loss: 0.041863990016281605\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 279, loss: 0.041791703552007675\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 280, loss: 0.04171985760331154\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 281, loss: 0.041648452170193195\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 282, loss: 0.0415774742141366\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 283, loss: 0.0415069255977869\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 284, loss: 0.04143681190907955\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 285, loss: 0.04136710334569216\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 286, loss: 0.04129782132804394\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 287, loss: 0.04122895561158657\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 288, loss: 0.04116049688309431\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 289, loss: 0.04109245166182518\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 290, loss: 0.041024806909263134\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 291, loss: 0.040957557037472725\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 292, loss: 0.040890698321163654\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 293, loss: 0.04082424007356167\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 294, loss: 0.04075816739350557\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 295, loss: 0.04069248307496309\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 296, loss: 0.04062718152999878\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 297, loss: 0.040562248788774014\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 298, loss: 0.04049770440906286\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 299, loss: 0.04043352697044611\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 300, loss: 0.040369720198214054\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 301, loss: 0.0403062766417861\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 302, loss: 0.04024319909512997\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 303, loss: 0.04018047917634249\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 304, loss: 0.0401181192137301\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 305, loss: 0.04005610244348645\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 306, loss: 0.03999444330111146\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 307, loss: 0.039933132007718086\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 308, loss: 0.03987216157838702\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 309, loss: 0.039811539463698864\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 310, loss: 0.039751249831169844\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 311, loss: 0.03969130478799343\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 312, loss: 0.03963168524205685\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 313, loss: 0.039572400506585836\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 314, loss: 0.03951343288645148\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 315, loss: 0.03945480240508914\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 316, loss: 0.039396487176418304\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 317, loss: 0.03933849465101957\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 318, loss: 0.03928081365302205\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 319, loss: 0.03922345256432891\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 320, loss: 0.03916640626266599\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 321, loss: 0.039109665900468826\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 322, loss: 0.03905322588980198\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 323, loss: 0.03899709740653634\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 324, loss: 0.03894126834347844\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 325, loss: 0.038885744754225016\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 326, loss: 0.038830508943647146\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 327, loss: 0.03877556370571256\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 328, loss: 0.038720918353646994\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 329, loss: 0.03866656171157956\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 330, loss: 0.03861248819157481\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 331, loss: 0.03855870896950364\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 332, loss: 0.03850521193817258\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 333, loss: 0.038451984990388155\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 334, loss: 0.03839903883635998\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 335, loss: 0.038346372079104185\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 336, loss: 0.03829398890957236\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 337, loss: 0.03824185533449054\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 338, loss: 0.03819000720977783\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 339, loss: 0.038138422183692455\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 340, loss: 0.03808710863813758\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 341, loss: 0.03803605120629072\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 342, loss: 0.037985258270055056\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 343, loss: 0.03793472796678543\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 344, loss: 0.037884445395320654\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 345, loss: 0.03783442825078964\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 346, loss: 0.03778466256335378\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 347, loss: 0.03773514274507761\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 348, loss: 0.03768586600199342\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 349, loss: 0.03763685096055269\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 350, loss: 0.03758807526901364\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 351, loss: 0.03753954079002142\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 352, loss: 0.03749125683680177\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 353, loss: 0.037443206645548344\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 354, loss: 0.03739539859816432\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 355, loss: 0.03734782570973039\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 356, loss: 0.03730047633871436\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 357, loss: 0.037253379821777344\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 358, loss: 0.03720650356262922\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 359, loss: 0.03715985966846347\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 360, loss: 0.037113435566425323\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 361, loss: 0.03706725174561143\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 362, loss: 0.03702127747237682\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 363, loss: 0.036975536961108446\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 364, loss: 0.03693000925704837\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 365, loss: 0.03688470972701907\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 366, loss: 0.03683961555361748\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 367, loss: 0.0367947556078434\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 368, loss: 0.03675010101869702\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 369, loss: 0.03670565877109766\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 370, loss: 0.036661427933722734\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 371, loss: 0.03661740059033036\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 372, loss: 0.0365735930390656\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 373, loss: 0.036529995035380125\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 374, loss: 0.03648659074679017\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 375, loss: 0.03644339367747307\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 376, loss: 0.03640039870515466\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 377, loss: 0.03635761374607682\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 378, loss: 0.03631502063944936\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 379, loss: 0.03627262683585286\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 380, loss: 0.03623043140396476\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 381, loss: 0.03618843061849475\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 382, loss: 0.03614662494510412\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 383, loss: 0.03610500926151872\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 384, loss: 0.03606358356773853\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 385, loss: 0.036022355780005455\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 386, loss: 0.035981313325464725\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 387, loss: 0.03594045294448733\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 388, loss: 0.035899777431041\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 389, loss: 0.0358592988923192\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 390, loss: 0.03581899730488658\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 391, loss: 0.03577888011932373\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 392, loss: 0.03573894081637263\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 393, loss: 0.035699176136404276\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 394, loss: 0.03565959818661213\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 395, loss: 0.035620194394141436\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 396, loss: 0.03558096941560507\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 397, loss: 0.03554191580042243\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 398, loss: 0.035503041464835405\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 399, loss: 0.03546433476731181\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 400, loss: 0.035425798036158085\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 401, loss: 0.0353874359279871\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 402, loss: 0.03534923540428281\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 403, loss: 0.03531121648848057\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 404, loss: 0.03527334751561284\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 405, loss: 0.03523565083742142\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 406, loss: 0.03519812133163214\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 407, loss: 0.035160756669938564\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 408, loss: 0.03512355266138911\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 409, loss: 0.03508650604635477\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 410, loss: 0.03504961868748069\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 411, loss: 0.03501289803534746\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 412, loss: 0.034976331517100334\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 413, loss: 0.034939922858029604\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 414, loss: 0.03490366414189339\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 415, loss: 0.03486756607890129\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 416, loss: 0.03483161982148886\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 417, loss: 0.03479582816362381\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 418, loss: 0.03476018365472555\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 419, loss: 0.034724696073681116\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 420, loss: 0.03468935890123248\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 421, loss: 0.03465416934341192\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 422, loss: 0.03461912786588073\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 423, loss: 0.03458422888070345\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 424, loss: 0.034549479372799397\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 425, loss: 0.03451488073915243\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 426, loss: 0.03448041435331106\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 427, loss: 0.034446099773049355\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 428, loss: 0.03441192535683513\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 429, loss: 0.03437788784503937\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 430, loss: 0.03434400539845228\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 431, loss: 0.03431024821475148\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 432, loss: 0.03427664004266262\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 433, loss: 0.03424315759912133\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 434, loss: 0.03420982277020812\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 435, loss: 0.03417661972343922\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 436, loss: 0.034143553115427494\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 437, loss: 0.03411061642691493\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 438, loss: 0.03407782083377242\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 439, loss: 0.03404515469446778\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 440, loss: 0.03401262313127518\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 441, loss: 0.03398021450266242\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 442, loss: 0.03394794324412942\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 443, loss: 0.033915800508111715\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 444, loss: 0.03388378769159317\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 445, loss: 0.03385189827531576\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 446, loss: 0.03382013505324721\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 447, loss: 0.03378850221633911\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 448, loss: 0.03375699184834957\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 449, loss: 0.03372562024742365\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 450, loss: 0.03369435667991638\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 451, loss: 0.0336632183752954\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 452, loss: 0.033632205333560705\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 453, loss: 0.033601319417357445\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 454, loss: 0.033570550847798586\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 455, loss: 0.033539891708642244\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 456, loss: 0.03350937506183982\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 457, loss: 0.03347895806655288\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 458, loss: 0.033448667731136084\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 459, loss: 0.03341848077252507\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 460, loss: 0.0333884353749454\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 461, loss: 0.03335848869755864\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 462, loss: 0.03332865796983242\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 463, loss: 0.033298949245363474\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 464, loss: 0.033269344829022884\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 465, loss: 0.03323986101895571\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 466, loss: 0.033210490830242634\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 467, loss: 0.03318122820928693\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 468, loss: 0.0331520838662982\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 469, loss: 0.03312303684651852\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 470, loss: 0.03309411834925413\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 471, loss: 0.033065290190279484\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 472, loss: 0.03303658403456211\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 473, loss: 0.03300798078998923\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 474, loss: 0.03297948790714145\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 475, loss: 0.03295109700411558\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 476, loss: 0.032922811806201935\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 477, loss: 0.03289464022964239\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 478, loss: 0.03286656551063061\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 479, loss: 0.03283860022202134\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 480, loss: 0.03281073598191142\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 481, loss: 0.032782977912575006\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 482, loss: 0.03275531670078635\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 483, loss: 0.03272776119410992\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 484, loss: 0.032700300216674805\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 485, loss: 0.03267295239493251\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 486, loss: 0.032645695842802525\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 487, loss: 0.032618540804833174\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 488, loss: 0.03259149007499218\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 489, loss: 0.03256453899666667\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 490, loss: 0.03253767779096961\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 491, loss: 0.032510919496417046\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 492, loss: 0.032484255731105804\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 493, loss: 0.0324576860293746\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 494, loss: 0.03243121691048145\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 495, loss: 0.032404838129878044\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 496, loss: 0.03237855760380626\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 497, loss: 0.03235237533226609\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 498, loss: 0.03232627362012863\n",
            "Test_acc: 1.0\n",
            "--------------------------\n",
            "Epoch 499, loss: 0.03230027947574854\n",
            "Test_acc: 1.0\n",
            "--------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6JiegNu4lx1"
      },
      "source": [
        "## 4. acc / loss可视化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7BIPLNt4lx2"
      },
      "source": [
        "### 4.1)绘制loss曲线"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7lFvcEE4lx3",
        "outputId": "478a934e-8f6e-4014-acea-1c2b0e31f160",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "plt.title('loss Function Curve')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(train_loss_results, label=\"$Loss$\")\n",
        "plt.legend()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f57b4640c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SWwaqDE4lx6"
      },
      "source": [
        "### 4.2)绘制Accuracy曲线"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH0Y7CM94lx7",
        "outputId": "bcdfbe11-7645-4439-88a3-d18ea67e5456",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "plt.title('ACC Curve')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Acc')\n",
        "plt.plot(test_acc, label=\"Accuracy\")\n",
        "plt.legend()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f57b45805c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}