{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.常用函数—实现某个函数对指定参数的求导运算 tf.GradientTape\n",
    "### with结构记录计算过程，gradient求出张量的梯度\n",
    "### with tf.GradientTape() as tape:\n",
    "#### 若干个计算过程\n",
    "### grad = tape.gradient(函数，对谁求导)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with tf.GradientTape() as tape:\n",
    "#    w = tf.Variable(tf.constant(3.0))\n",
    "#    loss = tf.pow(w,2)\n",
    "#grad = tape.gradient(loss, w)\n",
    "#print(grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.常用函数—枚举出每个元素并在元素前配上索引号 enumerate\n",
    "### enumerate可遍历每个元素(如列表/元组/字符串)，组合为：索引 元素，常在for循环中使用。\n",
    "### enumerate(列表名)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 one\n",
      "1 two\n",
      "2 three\n"
     ]
    }
   ],
   "source": [
    "seq = ['one','two','three']\n",
    "for i,element in enumerate(seq):\n",
    "    print(i,element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. 常用函数—独热码 tf.one_hot\n",
    "#### 独热编码：在分类问题中，常用独热码做标签，\n",
    "#### 标记类别：1表示是，0表示非。\n",
    "#### (0狗尾草鸢尾，1杂色鸢尾，2弗吉尼亚鸢尾)\n",
    "#### 标签：1\n",
    "#### 独热码：(0. 1. 0.) 表示百分之0的可能是狗尾鸢尾，百分之百的可能是杂色鸢尾，百分之0的可能是弗吉尼亚鸢尾"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.one_hot()函数将待转换数据，转换为one-hot形式的数据输出\n",
    "### tf.one_hot(待转换数据，depth=几分类)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "classes = 3\n",
    "labels = tf.constant([1,0,2])\n",
    "output = tf.one_hot(labels, depth=classes)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.常用函数—使每个输出值变为0到1之间的概率值，它们的和为1  tf.nn.softmax\n",
    "### 当n分类的n个输出通过softmax()函数，便符合概率分布。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After softmax, y_pro is: tf.Tensor([0.25598174 0.69583046 0.0481878 ], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "y = tf.constant([1.01, 2.01, -0.66])\n",
    "y_pro = tf.nn.softmax(y)\n",
    "print(\"After softmax, y_pro is:\", y_pro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.常用函数—assign_sub用于参数的自更新\n",
    "### 赋值操作，更新参数的值并返回\n",
    "### 调用assign_sub前，先用tf.Variable定义变量w为可训练(可自更新)。\n",
    "### w.assign_sub(w要自减的内容)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=3>\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(4)\n",
    "w.assign_sub(1)  # 这个操作表示w-=1即w=w-1\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.常用函数—返回张量沿指定维度最大值的索引号 tf.argmax\n",
    "### tf.argmax(张量名，axis=操作轴)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [2 3 4]\n",
      " [5 4 3]\n",
      " [8 7 2]]\n",
      "tf.Tensor([3 3 1], shape=(3,), dtype=int64)\n",
      "tf.Tensor([2 2 0 0], shape=(4,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "test = np.array([[1,2,3],[2,3,4],[5,4,3],[8,7,2]])\n",
    "print(test)\n",
    "print(tf.argmax(test, axis=0)) # 返回每一列最大值的索引\n",
    "print(tf.argmax(test, axis=1)) # 返回每一行最大值的索引"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
