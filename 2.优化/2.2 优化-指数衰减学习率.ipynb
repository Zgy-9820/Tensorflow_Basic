{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_gE5656K5B6e"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kcwf9vXO5B6j"
   },
   "source": [
    "### 可以先用较大的学习率，快速得道较优解，然后逐步减小学习率，使模型在训练后期稳定。\n",
    "### 指数衰减学习率 = 初始学习率 * 学习率衰减率 ** (当前轮数/多少轮衰减一次)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 713
    },
    "id": "qZTJ7HgV6PsM",
    "outputId": "5767fe6c-5b02-4727-b749-d14968260792"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 epoch, w is 2.5999999046325684, loss is 36.0, lr is 0.2\n",
      "After 1 epoch, w is 1.174399971961975, loss is 12.959999084472656, lr is 0.198\n",
      "After 2 epoch, w is 0.32194823026657104, loss is 4.728014945983887, lr is 0.19602\n",
      "After 3 epoch, w is -0.1911258101463318, loss is 1.7475472688674927, lr is 0.1940598\n",
      "After 4 epoch, w is -0.5019263029098511, loss is 0.6542774438858032, lr is 0.192119202\n",
      "After 5 epoch, w is -0.6913915276527405, loss is 0.2480774074792862, lr is 0.19019800998\n",
      "After 6 epoch, w is -0.8076110482215881, loss is 0.09523919224739075, lr is 0.1882960298802\n",
      "After 7 epoch, w is -0.8793386816978455, loss is 0.03701350837945938, lr is 0.186413069581398\n",
      "After 8 epoch, w is -0.9238744974136353, loss is 0.014559153467416763, lr is 0.18454893888558402\n",
      "After 9 epoch, w is -0.9516912698745728, loss is 0.005795092321932316, lr is 0.18270344949672818\n",
      "After 10 epoch, w is -0.9691671133041382, loss is 0.0023337334860116243, lr is 0.18087641500176088\n",
      "After 11 epoch, w is -0.980209469795227, loss is 0.0009506669011898339, lr is 0.17906765085174328\n",
      "After 12 epoch, w is -0.9872263073921204, loss is 0.0003916650894097984, lr is 0.17727697434322587\n",
      "After 13 epoch, w is -0.9917100071907043, loss is 0.00016316722030751407, lr is 0.17550420459979357\n",
      "After 14 epoch, w is -0.9945907592773438, loss is 6.872398080304265e-05, lr is 0.17374916255379566\n",
      "After 15 epoch, w is -0.9964516758918762, loss is 2.925988519564271e-05, lr is 0.1720116709282577\n",
      "After 16 epoch, w is -0.9976601600646973, loss is 1.2590603546414059e-05, lr is 0.17029155421897513\n",
      "After 17 epoch, w is -0.9984490871429443, loss is 5.474850695463829e-06, lr is 0.16858863867678536\n",
      "After 18 epoch, w is -0.9989668130874634, loss is 2.405330633337144e-06, lr is 0.1669027522900175\n",
      "After 19 epoch, w is -0.9993082284927368, loss is 1.0674751820261008e-06, lr is 0.16523372476711734\n",
      "After 20 epoch, w is -0.999534547328949, loss is 4.785478040503222e-07, lr is 0.16358138751944618\n",
      "After 21 epoch, w is -0.9996852874755859, loss is 2.1664618543582037e-07, lr is 0.1619455736442517\n",
      "After 22 epoch, w is -0.9997861981391907, loss is 9.904397302307189e-08, lr is 0.16032611790780918\n",
      "After 23 epoch, w is -0.9998540878295898, loss is 4.571123568553048e-08, lr is 0.1587228567287311\n",
      "After 24 epoch, w is -0.9998999238014221, loss is 2.1290361473802477e-08, lr is 0.15713562816144377\n",
      "After 25 epoch, w is -0.9999310374259949, loss is 1.0015245521799443e-08, lr is 0.15556427187982935\n",
      "After 26 epoch, w is -0.9999522566795349, loss is 4.755836613412612e-09, lr is 0.15400862916103103\n",
      "After 27 epoch, w is -0.9999668002128601, loss is 2.27942464903208e-09, lr is 0.15246854286942071\n",
      "After 28 epoch, w is -0.9999768137931824, loss is 1.1022258661341766e-09, lr is 0.15094385744072653\n",
      "After 29 epoch, w is -0.9999837279319763, loss is 5.376001865897706e-10, lr is 0.14943441886631922\n",
      "After 30 epoch, w is -0.9999885559082031, loss is 2.6478019776732253e-10, lr is 0.14794007467765605\n",
      "After 31 epoch, w is -0.9999918937683105, loss is 1.3096723705530167e-10, lr is 0.1464606739308795\n",
      "After 32 epoch, w is -0.9999942183494568, loss is 6.571099220309407e-11, lr is 0.14499606719157068\n",
      "After 33 epoch, w is -0.9999958872795105, loss is 3.3427483003833913e-11, lr is 0.143546106519655\n",
      "After 34 epoch, w is -0.999997079372406, loss is 1.6914469824769185e-11, lr is 0.14211064545445842\n",
      "After 35 epoch, w is -0.9999979138374329, loss is 8.530065542800003e-12, lr is 0.14068953899991385\n",
      "After 36 epoch, w is -0.9999985098838806, loss is 4.352074256530614e-12, lr is 0.13928264360991469\n",
      "After 37 epoch, w is -0.999998927116394, loss is 2.220446049250313e-12, lr is 0.13788981717381554\n",
      "After 38 epoch, w is -0.9999992251396179, loss is 1.1510792319313623e-12, lr is 0.1365109190020774\n",
      "After 39 epoch, w is -0.999999463558197, loss is 6.004086117172847e-13, lr is 0.13514580981205662\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(tf.constant(5, dtype=tf.float32))\n",
    "\n",
    "epoch = 40\n",
    "LR_BASE = 0.2  # 最初学习率\n",
    "LR_DECAY = 0.99  # 学习率衰减率\n",
    "LR_STEP = 1  # 喂入多少轮BATCH_SIZE后，更新一次学习率\n",
    "\n",
    "for epoch in range(epoch):  # for epoch 定义顶层循环，表示对数据集循环epoch次，此例数据集数据仅有1个w,初始化时候constant赋值为5，循环100次迭代。\n",
    "    lr = LR_BASE * LR_DECAY ** (epoch / LR_STEP)\n",
    "    with tf.GradientTape() as tape:  # with结构到grads框起了梯度的计算过程。\n",
    "        loss = tf.square(w + 1)\n",
    "    grads = tape.gradient(loss, w)  # .gradient函数告知谁对谁求导\n",
    "\n",
    "    w.assign_sub(lr * grads)  # .assign_sub 对变量做自减 即：w -= lr*grads 即 w = w - lr*grads\n",
    "    print(\"After {} epoch, w is {}, loss is {}, lr is {}\".format(epoch, w.numpy(), loss, lr))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "05 优化-指数衰减学习率.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
